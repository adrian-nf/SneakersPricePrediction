{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fff7c209-12e1-40f1-a4f8-0b82b602c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sweetviz as sv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c0fcc-df83-4537-9514-41c8ed45b3c5",
   "metadata": {},
   "source": [
    "# Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec2382e-6e7b-47f2-9c76-a9c26fd848d3",
   "metadata": {},
   "source": [
    "## Se carga el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fbf41aa-a4cb-415b-8cf8-bd1bf2b7644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv(\"../data/original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307b590c-75bf-4633-b37c-0552267a3b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = original.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4757ae-021d-44c5-8ae6-24decd5a75b2",
   "metadata": {},
   "source": [
    "## Comprobación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bee9945-6938-4a98-8400-645b5f5a3b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order Date      0\n",
       "Brand           0\n",
       "Sneaker Name    0\n",
       "Sale Price      0\n",
       "Retail Price    0\n",
       "Release Date    0\n",
       "Shoe Size       0\n",
       "Buyer Region    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4fb643b-55c7-4a21-a26c-76529241fc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order Date       object\n",
       "Brand            object\n",
       "Sneaker Name     object\n",
       "Sale Price       object\n",
       "Retail Price     object\n",
       "Release Date     object\n",
       "Shoe Size       float64\n",
       "Buyer Region     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b7ead4-1256-461f-b706-1ff81490e364",
   "metadata": {},
   "source": [
    "## Limpieza del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51e1b2a-3635-45ba-a86b-171aa066c02f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Limpieza de la variable \"Sneaker Name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3359bbd-8040-4b59-aa04-a5b0e6a5c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sneakers(original_data):\n",
    "    products = original_data[\"Sneaker Name\"].unique()\n",
    "    # Normalizar nombres de marcas (capitalizar 'adidas' a 'Adidas')\n",
    "    normalized_products = [product.replace('adidas', 'Adidas') for product in products]\n",
    "    \n",
    "    # Listas predefinidas de términos conocidos\n",
    "    brands = ['Nike', 'Adidas']\n",
    "    sub_brands = ['Yeezy', 'Air Jordan']\n",
    "    sub_brand_to_brand = {\n",
    "        'Yeezy': 'Adidas',\n",
    "        'Air Jordan': 'Nike'\n",
    "    }\n",
    "    collaborations = ['Off-White', 'Off White', 'Virgil Abloh']\n",
    "    product_lines = [\n",
    "        'Boost',\n",
    "        'Air Max',\n",
    "        'Air Presto',\n",
    "        'Air VaporMax',\n",
    "        'Air Force 1',\n",
    "        'Blazer Mid',\n",
    "        'Zoom Fly',\n",
    "        'React Hyperdunk',\n",
    "        'Hyperdunk',\n",
    "        'Mercurial',\n",
    "        'Retro',\n",
    "        'Flyknit'\n",
    "    ]\n",
    "    models = ['350', '90', '97', '1']\n",
    "    versions = ['V2', 'V3', '2pt0']\n",
    "    heights = ['Low', 'Mid', 'High']\n",
    "    years = ['2015', '2016', '2017', '2018']\n",
    "    # Lista de colores extendida y organizada\n",
    "    colors = [\n",
    "        'Beluga', 'Core Black Copper', 'Core Black Green', 'Core Black Red', 'Core Black White',\n",
    "        'Cream White', 'Zebra', 'Moonrock', 'Pirate Black', 'Oxford Tan', 'Turtledove',\n",
    "        'Semi Frozen Yellow', 'Blue Tint', 'Black', 'Desert Ore', 'Elemental Rose Queen',\n",
    "        'All Hallows Eve', 'Grim Reaper', 'Sesame', 'Wolf Grey', 'Menta', 'Black Silver',\n",
    "        'Pink', 'Volt', 'Butter', 'Static', 'Static Reflective', 'Chicago', 'University Blue',\n",
    "        'White', 'Black-White', 'Black-Silver', 'Total-Orange'\n",
    "    ]\n",
    "    \n",
    "    # Función auxiliar para verificar y asignar tokens\n",
    "    def assign_tokens(tokens):\n",
    "        data = {\n",
    "            'Sneaker Name': None,\n",
    "            'Brand': None,\n",
    "            'Sub-brand': None,\n",
    "            'Product Line': None,\n",
    "            'Model': None,\n",
    "            'Version': None,\n",
    "            'Height': None,\n",
    "            'Collaboration': None,\n",
    "            'Color(s)': [],\n",
    "            'Year': None\n",
    "        }\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            token = tokens[i]\n",
    "    \n",
    "            # Manejo de tokens de múltiples palabras\n",
    "            if i < len(tokens) - 1:\n",
    "                next_token = tokens[i+1]\n",
    "                combined_token = f\"{token} {next_token}\"\n",
    "                combined_token_hyphen = f\"{token}-{next_token}\"  # Para colores como 'Black-White'\n",
    "    \n",
    "                # Verificar combinaciones con guiones (ej. 'Black-White')\n",
    "                if combined_token_hyphen in colors:\n",
    "                    data['Color(s)'].append(combined_token_hyphen)\n",
    "                    i += 2\n",
    "                    continue\n",
    "    \n",
    "                # Verificar combinaciones de dos palabras sin guión\n",
    "                if combined_token in sub_brands:\n",
    "                    data['Sub-brand'] = combined_token\n",
    "                    # Asignar Brand basado en Sub-brand\n",
    "                    data['Brand'] = sub_brand_to_brand.get(combined_token, data['Brand'])\n",
    "                    i += 2\n",
    "                    continue\n",
    "                if combined_token in product_lines:\n",
    "                    data['Product Line'] = combined_token\n",
    "                    i += 2\n",
    "                    continue\n",
    "                if combined_token in collaborations:\n",
    "                    data['Collaboration'] = combined_token\n",
    "                    i += 2\n",
    "                    continue\n",
    "                if combined_token in versions:\n",
    "                    data['Version'] = combined_token\n",
    "                    i += 2\n",
    "                    continue\n",
    "                if combined_token in colors:\n",
    "                    data['Color(s)'].append(combined_token)\n",
    "                    i += 2\n",
    "                    continue\n",
    "                if combined_token in heights:\n",
    "                    data['Height'] = combined_token\n",
    "                    i += 2\n",
    "                    continue\n",
    "    \n",
    "            # Verificaciones de un solo token\n",
    "            if token in brands:\n",
    "                data['Brand'] = token\n",
    "            elif token in sub_brands:\n",
    "                data['Sub-brand'] = token\n",
    "                # Asignar Brand basado en Sub-brand si Brand no está ya asignado\n",
    "                if not data['Brand']:\n",
    "                    data['Brand'] = sub_brand_to_brand.get(token, data['Brand'])\n",
    "            elif token in product_lines:\n",
    "                data['Product Line'] = token\n",
    "            elif token in models:\n",
    "                data['Model'] = token\n",
    "            elif token in versions:\n",
    "                data['Version'] = token\n",
    "            elif token in heights:\n",
    "                data['Height'] = token\n",
    "            elif token in collaborations:\n",
    "                data['Collaboration'] = token\n",
    "            elif token in years:\n",
    "                data['Year'] = token\n",
    "            elif token in colors:\n",
    "                data['Color(s)'].append(token)\n",
    "            else:\n",
    "                # Asumir que tokens no reconocidos son parte del color\n",
    "                data['Color(s)'].append(token)\n",
    "            i += 1\n",
    "    \n",
    "        # Asignar Brand basado en Sub-brand si Brand no está ya asignado\n",
    "        if not data['Brand'] and data['Sub-brand']:\n",
    "            data['Brand'] = sub_brand_to_brand.get(data['Sub-brand'], None)\n",
    "    \n",
    "        return data\n",
    "    \n",
    "    # Analizar cada producto\n",
    "    parsed_data = []\n",
    "    for product in normalized_products:\n",
    "        tokens = product.split('-')\n",
    "        parsed = assign_tokens(tokens)\n",
    "        parsed['Sneaker Name'] = product\n",
    "        parsed_data.append(parsed)\n",
    "    \n",
    "    # Crear DataFrame\n",
    "    df = pd.DataFrame(parsed_data)\n",
    "    \n",
    "    # Reorganizar columnas para mejor legibilidad\n",
    "    df = df[['Sneaker Name', 'Brand', 'Sub-brand', 'Product Line', 'Model', 'Version', 'Height', 'Collaboration', 'Color(s)', 'Year']]\n",
    "\n",
    "    if 'Brand' in original_data.columns:\n",
    "        original_data.drop(columns=['Brand'], inplace=True)\n",
    "    \n",
    "    # Unir el dataframe original por \"Sneaker Name\"\n",
    "    merged_data = pd.merge(original_data, df, on=\"Sneaker Name\", how=\"left\")\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176b7e42-895f-418d-a167-38d68ddee718",
   "metadata": {},
   "source": [
    "### Preparación del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf298d9-0cfd-4d12-88f9-ec5a0809b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data):\n",
    "    data['Sale Price'] = data['Sale Price'].astype(str).str.replace('$', '', regex=False).str.replace(',', '', regex=False).astype(float)\n",
    "    data['Retail Price'] = data['Retail Price'].astype(str).str.replace('$', '', regex=False).str.replace(',', '', regex=False).astype(float)\n",
    "    data['Order Date'] = pd.to_datetime(data['Order Date'], format='%m/%d/%y')\n",
    "    data['Release Date'] = pd.to_datetime(data['Release Date'], format='%m/%d/%y')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd3598c-e1b4-4bb1-885e-229a2ecfd7d2",
   "metadata": {},
   "source": [
    "### Analisis de los datos usando Sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecc022f7-dfdc-4292-8b00-ba763231e7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07feeb3f59a4cf4b9dc26340dc0614d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |                                             | [  0%]   00:00 ->…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report reports/report_general.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "full_dataset_sv = clean_sneakers(prepare_dataset(full_dataset.copy()))\n",
    "full_dataset_sv['Color(s)'] = full_dataset_sv['Color(s)'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "full_dataset_sv['Color(s)'] = full_dataset_sv['Color(s)'].apply(lambda x: ', '.join(map(str, x)))\n",
    "my_report = sv.analyze(full_dataset_sv, target_feat=\"Sale Price\")\n",
    "my_report.show_html(\"reports/report_general.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee828a5-67e6-400e-bb7e-22c6a8c4d3d0",
   "metadata": {},
   "source": [
    "#### Se guarda para usarlo para hacer gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "122d7b22-5118-4eb7-b3f6-06c1a7b1c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_dataset_sv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "661375e8-84cd-4ded-9e94-f9d41431aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('../data/data_graphics.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ae0e79-b425-45a7-bfbd-08f203b15279",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Limpieza del dataset simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "667c9aa4-859b-461c-99f3-24b426e8f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset_simple(data, data_scaler, dtype):\n",
    "    #categorical_cols = ['Brand', 'Sneaker Name', 'Buyer Region']\n",
    "    categorical_cols = ['Brand', 'Buyer Region']\n",
    "    numerical_cols = ['Sale Price', 'Retail Price', 'Shoe Size']\n",
    "    \n",
    "    if dtype != \"test\":\n",
    "        numerical_cols.remove(\"Sale Price\")\n",
    "\n",
    "    # Nombre\n",
    "    data['Sneaker Name'] = data['Sneaker Name'].str.replace(\"adidas\", \"Adidas\")\n",
    "    data[\"Boost\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"Boost\" in x.split(\"-\") else 0)\n",
    "    data[\"Jordan\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"Jordan\" in x.split(\"-\") else 0)\n",
    "    data[\"V2\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"V2\" in x.split(\"-\") else 0)\n",
    "    data[\"Core\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"Core\" in x.split(\"-\") else 0)\n",
    "    data[\"Low\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"Low\" in x.split(\"-\") else 0)\n",
    "    data[\"350\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"350\" in x.split(\"-\") else 0)\n",
    "    data[\"Adidas\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"Adidas\" in x.split(\"-\") else 0)\n",
    "    data[\"Nike\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"Nike\" in x.split(\"-\") else 0)\n",
    "    data[\"Air\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"Air\" in x.split(\"-\") else 0)\n",
    "    data[\"Zoom\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"Zoom\" in x.split(\"-\") else 0)\n",
    "    data[\"Blazer\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"Blazer\" in x.split(\"-\") else 0)\n",
    "    data[\"Retro\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"Retro\" in x.split(\"-\") else 0)\n",
    "    data[\"Force\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"Force\" in x.split(\"-\") else 0)\n",
    "    data[\"Max\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"Max\" in x.split(\"-\") else 0)\n",
    "    data[\"Black\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"Black\" in x.split(\"-\") else 0)\n",
    "    data[\"Vapormax\"] = data[\"Sneaker Name\"].apply(lambda x: 1 if \"Vapormax\" in x.split(\"-\") else 0)\n",
    "    \n",
    "\n",
    "    # Prueba\n",
    "    data = data.drop(\"Sneaker Name\", axis=1)\n",
    "\n",
    "    # Fechas\n",
    "    data['Order Year'] = data['Order Date'].dt.year\n",
    "    data['Order Month'] = data['Order Date'].dt.month\n",
    "    data['Order Day'] = data['Order Date'].dt.day\n",
    "    data['Order Day of Week'] = data['Order Date'].dt.dayofweek\n",
    "    \n",
    "    data['Release Year'] = data['Release Date'].dt.year\n",
    "    data['Release Month'] = data['Release Date'].dt.month\n",
    "    data['Release Day'] = data['Release Date'].dt.day\n",
    "    data['Release Day of Week'] = data['Release Date'].dt.dayofweek\n",
    "    \n",
    "    data['Order Date'] = data['Order Date'].astype(np.int64) // 10**9\n",
    "    data['Release Date'] = data['Release Date'].astype(np.int64) // 10**9\n",
    "\n",
    "    # Variables Categóricas\n",
    "    data = pd.get_dummies(data, columns=categorical_cols)\n",
    "\n",
    "    # Variables Numéricas\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data_scaler[numerical_cols])\n",
    "    data[numerical_cols] = scaler.transform(data[numerical_cols])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d621615-9969-4a9d-b61b-4d21ee3e4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset0 = prepare_dataset(full_dataset.copy())\n",
    "full_dataset1 = clean_dataset_simple(full_dataset0.copy(), full_dataset0.copy(), \"train\")\n",
    "X = full_dataset1.loc[:, full_dataset1.columns != \"Sale Price\"]\n",
    "y = full_dataset1.loc[:, \"Sale Price\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acbf1f9-f205-4343-b6ad-23b53b569da7",
   "metadata": {},
   "source": [
    "### Limpieza del dataset complejo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66a54931-cebd-4b93-8b53-4d478790e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(data):\n",
    "    data_scaler = data.copy()\n",
    "    categorical_cols = ['Brand', 'Sub-brand', 'Product Line', 'Model', 'Version', 'Height', 'Collaboration']\n",
    "    numerical_cols = ['Sale Price', 'Retail Price', 'Shoe Size']\n",
    "    \n",
    "    numerical_cols.remove(\"Sale Price\")\n",
    "    \n",
    "    # Eliminar columnas\n",
    "    data = data.drop(\"Buyer Region\", axis=1)\n",
    "    data = data.drop(\"Sneaker Name\", axis=1)\n",
    "    data = data.drop(\"Year\", axis=1)\n",
    "    \n",
    "    # Fechas\n",
    "    data['Order Year'] = data['Order Date'].dt.year\n",
    "    data['Order Month'] = data['Order Date'].dt.month\n",
    "    data['Order Day'] = data['Order Date'].dt.day\n",
    "    data['Order Day of Week'] = data['Order Date'].dt.dayofweek\n",
    "    \n",
    "    data['Release Year'] = data['Release Date'].dt.year\n",
    "    data['Release Month'] = data['Release Date'].dt.month\n",
    "    data['Release Day'] = data['Release Date'].dt.day\n",
    "    data['Release Day of Week'] = data['Release Date'].dt.dayofweek\n",
    "\n",
    "    #data['Order Month sin'] = np.sin(2 * np.pi * data['Order Month'] / 12)\n",
    "    #data['Release Month sin'] = np.sin(2 * np.pi * data['Release Month'] / 12)\n",
    "    #data['Order Month cos'] = np.cos(2 * np.pi * data['Order Month'] / 12)\n",
    "    #data['Release Month cos'] = np.cos(2 * np.pi * data['Release Month'] / 12)\n",
    "    \n",
    "    data['Order Date'] = data['Order Date'].astype(np.int64) // 10**9\n",
    "    data['Release Date'] = data['Release Date'].astype(np.int64) // 10**9\n",
    "    #data.drop(columns='Order Date', inplace=True)\n",
    "    #data.drop(columns='Release Date', inplace=True)\n",
    "    \n",
    "    # Variables Categóricas\n",
    "    data = pd.get_dummies(data, columns=categorical_cols)\n",
    "\n",
    "    # Colores\n",
    "    unique_colors = set()\n",
    "    for sublist in data['Color(s)']:\n",
    "        if isinstance(sublist, list):\n",
    "            unique_colors.update(sublist)\n",
    "\n",
    "    for color in unique_colors:\n",
    "        data['Color_'+color] = 0\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        colors = row['Color(s)']\n",
    "        if isinstance(colors, list):\n",
    "            for color in colors:\n",
    "                data.at[index, 'Color_'+color] = 1\n",
    "    \n",
    "    data.drop(columns='Color(s)', inplace=True)\n",
    "    \n",
    "    # Variables Numéricas\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data_scaler[numerical_cols])\n",
    "    data[numerical_cols] = scaler.transform(data[numerical_cols])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c82735e-f091-4473-a547-173addf5f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset0 = clean_sneakers(prepare_dataset(full_dataset.copy()))\n",
    "full_dataset1 = clean_dataset(full_dataset0.copy())\n",
    "X = full_dataset1.loc[:, full_dataset1.columns != \"Sale Price\"]\n",
    "y = full_dataset1.loc[:, \"Sale Price\"]\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3556ebb-9658-400f-b26d-b97dbe7aecad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    99956.000000\n",
       "mean       446.634719\n",
       "std        255.982969\n",
       "min        186.000000\n",
       "25%        275.000000\n",
       "50%        370.000000\n",
       "75%        540.000000\n",
       "max       4050.000000\n",
       "Name: Sale Price, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset0[\"Sale Price\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8707f8a0-f084-48c6-bc51-b234ddc16495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    79964.000000\n",
       "mean        -0.002639\n",
       "std          1.001645\n",
       "min         -1.018177\n",
       "25%         -0.670496\n",
       "50%         -0.299376\n",
       "75%          0.364734\n",
       "max         14.076653\n",
       "Name: Sale Price, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bfbe3a-7471-435c-a435-ebd126414efe",
   "metadata": {},
   "source": [
    "## Comprobar la distribución de los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e1fa71-baa2-4bf8-a4f6-80cc6bb74d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe3de65f8b14170924d371f78655414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |                                             | [  0%]   00:00 ->…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report reports/report_train_test.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "#full_dataset_sv = clean_sneakers(prepare_dataset(full_dataset.copy()))\n",
    "#full_dataset_sv['Color(s)'] = full_dataset_sv['Color(s)'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "#full_dataset_sv['Color(s)'] = full_dataset_sv['Color(s)'].apply(lambda x: ', '.join(map(str, x)))\n",
    "#train_sv, test_sv = train_test_split(full_dataset_sv, test_size=0.2, random_state=42)\n",
    "\n",
    "train_sv = pd.concat([X_train_full, y_train_full], axis=1)\n",
    "test_sv = pd.concat([X_test, y_test], axis=1)\n",
    "train_sv = train_sv.select_dtypes(include=['int64', 'float64'])\n",
    "test_sv = test_sv.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "my_report = sv.compare([train_sv, \"Train\"], [test_sv, \"Test\"], target_feat=\"Sale Price\")\n",
    "my_report.show_html(\"reports/report_train_test.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d6d1776-381a-4c1e-81be-bfabdc3ac75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abcbcfc113c849bb8c481a0e99d2ee6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |                                             | [  0%]   00:00 ->…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report reports/report_train_val.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "train_sv = pd.concat([X_train, y_train], axis=1)\n",
    "val_sv = pd.concat([X_val, y_val], axis=1)\n",
    "train_sv = train_sv.select_dtypes(include=['int64', 'float64'])\n",
    "val_sv = val_sv.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "my_report = sv.compare([train_sv, \"Train\"], [val_sv, \"Val\"], target_feat=\"Sale Price\")\n",
    "my_report.show_html(\"reports/report_train_val.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2283a90-aef3-417e-b285-9109bb8a1792",
   "metadata": {},
   "source": [
    "## Guardar Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a5331e13-cf2f-4338-9041-136939b16a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full.to_csv('../data/X_train_full.csv', index=False)\n",
    "y_train_full.to_csv('../data/y_train_full.csv', index=False)\n",
    "X_test.to_csv('../data/X_test.csv', index=False)\n",
    "y_test.to_csv('../data/y_test.csv', index=False)\n",
    "X_train.to_csv('../data/X_train.csv', index=False)\n",
    "y_train.to_csv('../data/y_train.csv', index=False)\n",
    "X_val.to_csv('../data/X_val.csv', index=False)\n",
    "y_val.to_csv('../data/y_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a05a9f9-e81a-480e-baef-b3134bd924a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
